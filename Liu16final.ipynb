{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the following packages before running the code:\n",
    "1/ cv2\n",
    "2/ tqdm\n",
    "3/ densratio\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "''' Import relevant libraries'''\n",
    "\n",
    "import cv2 # using opencv to process image\n",
    "from tqdm import tqdm  # use tqdm to know the process of the iteration\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os         \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from densratio import densratio\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "train_path = r'C:\\Users\\phuph\\Desktop\\Spiderdatabase\\spidertrainset'\n",
    "csv_path = r'C:\\Users\\phuph\\Desktop\\Spiderdatabase\\spider_csv.csv'\n",
    "#test_path = 'test'\n",
    "\n",
    "size_img = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" From the image, record the label either dangerous or non\"\"\"\n",
    "def record_label(image_name):\n",
    "    label = image_name.split('.')[0]\n",
    "    if label == 'dangerous':\n",
    "        return 1\n",
    "    elif label == 'non':\n",
    "        return 0\n",
    "\n",
    "def create_train():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(train_path)):\n",
    "        path = os.path.join(train_path, img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_COLOR).astype(float)\n",
    "        img_data = cv2.resize(img_data, (size_img, size_img))\n",
    "        training_data.append([img_data, record_label(img) ])\n",
    "    #np.save('train_data.npy', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1005/1005 [00:16<00:00, 60.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train = create_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_train = []\n",
    "for i in train:\n",
    "    a = i[0].reshape(-1)\n",
    "    A_train.append(a)\n",
    "A_train = np.asarray(A_train)\n",
    "B_train = np.asarray([i[1] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuph\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train0, X_test0, Y_train, Y_test = train_test_split(A_train, B_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train1 = scaler.fit_transform(X_train0)\n",
    "X_test1 = scaler.fit_transform(X_test0)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_train = pca.fit_transform(X_train1)\n",
    "X_test= pca.transform(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nY_new_list = []\\nfor i in range(5):\\n    rho_po = random.choice(rho_po_list)\\n    rho_ne = random.choice(rho_ne_list)\\n    Y_temp = Y_train * (np.cumsum(Y_train) <= (1 - rho_po) * sum(Y_train))\\n    s = 1 - (1 - Y_train) * (np.cumsum(1 - Y_train) <= (1 - rho_ne) * sum(1 - Y_train))\\n    Y_temp[Y_train==0] = s[Y_train==0]\\n    Y_new_list.append([Y_temp,rho_po,rho_ne])\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Induce CCN flip rates'''\n",
    "\n",
    "import random\n",
    "rho_po_list = [0.1,0.2,0.3,0.4,0.4]\n",
    "rho_ne_list = [0.3,0.1,0.4,0.1,0.4]\n",
    "Y_new_list = []\n",
    "for i in range(5):\n",
    "    rho_po = rho_po_list[i]\n",
    "    rho_ne = rho_ne_list[i]\n",
    "    Y_temp = np.copy(Y_train)\n",
    "    for j in range(len(Y_temp)):\n",
    "        if Y_train[j] ==1:\n",
    "            temp = random.random()\n",
    "            if temp < rho_po:\n",
    "                Y_temp[j] = 0\n",
    "        else:\n",
    "            t = random.random()\n",
    "            if t < rho_ne:\n",
    "                Y_temp[j] = 1\n",
    "    Y_new_list.append([Y_temp,rho_po,rho_ne])\n",
    "'''\n",
    "Y_new_list = []\n",
    "for i in range(5):\n",
    "    rho_po = random.choice(rho_po_list)\n",
    "    rho_ne = random.choice(rho_ne_list)\n",
    "    Y_temp = Y_train * (np.cumsum(Y_train) <= (1 - rho_po) * sum(Y_train))\n",
    "    s = 1 - (1 - Y_train) * (np.cumsum(1 - Y_train) <= (1 - rho_ne) * sum(1 - Y_train))\n",
    "    Y_temp[Y_train==0] = s[Y_train==0]\n",
    "    Y_new_list.append([Y_temp,rho_po,rho_ne])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Import R and KLIEP'''\n",
    "\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "r = robjects.r\n",
    "#from rpy2.robjects.packages import importr\n",
    "#utils = importr(\"densratio\")\n",
    "import rpy2.robjects.numpy2ri as numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "robjects.r('''\n",
    "           f <- function(t,t1) {\n",
    "\n",
    "                    library(densratio)\n",
    "                    dens <- densratio(x = t, y = t1, method = \"KLIEP\")\n",
    "                    result <-dens$compute_density_ratio(t1)\n",
    "            }\n",
    "            ''')\n",
    "kliep_check = robjects.globalenv['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Using KLIEP function to estimate noise'''\n",
    "\n",
    "def KLIEP_e(X,Y):\n",
    "    e_list=[]\n",
    "    X_rho_po= X[Y ==1]\n",
    "    X_rho_ne= X[Y ==0]\n",
    "    result_po= kliep_check(X_rho_po,X)\n",
    "    result_ne= kliep_check(X_rho_ne,X)\n",
    "    Po = np.asarray(result_po)\n",
    "    Ne = np.asarray(result_ne)\n",
    "    n = len(X)\n",
    "    py_po = sum(1 for i in Y if i==1)/n\n",
    "    py_ne = sum(1 for i in Y if i==0)/n\n",
    "    Po_n = min(Po*py_po)\n",
    "    Ne_n = min(Ne*py_ne)\n",
    "    e_list.append([Ne_n,Po_n])\n",
    "    return e_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Using KLIEP to return the beta weight'''\n",
    "\n",
    "def KLIEP_betas(X,Y):\n",
    "    e_list=[]\n",
    "    X_rho_po= X[Y ==1]\n",
    "    X_rho_ne= X[Y ==0]\n",
    "    result_po= kliep_check(X_rho_po,X)\n",
    "    result_ne= kliep_check(X_rho_ne,X)\n",
    "    Po = np.asarray(result_po)\n",
    "    Ne = np.asarray(result_ne)\n",
    "    n = len(X)\n",
    "    py_po = sum(1 for i in Y if i==1)/n\n",
    "    py_ne = sum(1 for i in Y if i==0)/n\n",
    "    Po_n = min(Po*py_po)\n",
    "    Ne_n = min(Ne*py_ne)\n",
    "    betas = np.ones((n,), dtype = None)\n",
    "    for i in range(n):\n",
    "        if Y[i] == 0:\n",
    "            if Po[i] == 0:\n",
    "                betas[i] = 0\n",
    "            else:\n",
    "                betas[i] = (Po[i]*py_po - Po_n)/ ((1-Po_n-Ne_n)*Po[i]*py_po)\n",
    "        else: \n",
    "            if Ne[i] == 0:\n",
    "                betas[i] =0\n",
    "            else:\n",
    "                betas[i] = (Ne[i]*py_ne - Ne_n)/ ((1-Po_n-Ne_n)*Ne[i]*py_ne)\n",
    "\n",
    "    return betas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 20 \n",
      "Number of classes: 2\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "''' Neural network model'''\n",
    "\n",
    "dims = X_train.shape[1]\n",
    "n_y = 2\n",
    "print( 'Number of features: %d ' %dims)\n",
    "print( 'Number of classes: %d' %n_y)\n",
    "print(\"Building model...\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_shape=(dims,)))\n",
    "model.add(Dense(60, input_shape=(dims,)))\n",
    "model.add(Dense(40, input_shape=(dims,)))\n",
    "model.add(Dense(n_y, input_shape=(dims,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',sample_weight_mode=None,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.9805 - acc: 0.531 - ETA: 0s - loss: 0.8324 - acc: 0.460 - ETA: 0s - loss: 0.7458 - acc: 0.486 - ETA: 0s - loss: 0.7323 - acc: 0.500 - ETA: 0s - loss: 0.7086 - acc: 0.488 - ETA: 0s - loss: 0.6982 - acc: 0.486 - ETA: 0s - loss: 0.6883 - acc: 0.498 - ETA: 0s - loss: 0.6925 - acc: 0.487 - ETA: 0s - loss: 0.6857 - acc: 0.483 - 0s - loss: 0.6840 - acc: 0.4851     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.6962 - acc: 0.500 - ETA: 0s - loss: 0.6064 - acc: 0.606 - ETA: 0s - loss: 0.6298 - acc: 0.605 - ETA: 0s - loss: 0.6358 - acc: 0.596 - ETA: 0s - loss: 0.6308 - acc: 0.597 - ETA: 0s - loss: 0.6349 - acc: 0.593 - ETA: 0s - loss: 0.6315 - acc: 0.595 - ETA: 0s - loss: 0.6340 - acc: 0.591 - 0s - loss: 0.6340 - acc: 0.5908     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.6474 - acc: 0.656 - ETA: 0s - loss: 0.7506 - acc: 0.525 - ETA: 0s - loss: 0.7444 - acc: 0.506 - ETA: 0s - loss: 0.7299 - acc: 0.490 - ETA: 0s - loss: 0.7257 - acc: 0.496 - ETA: 0s - loss: 0.7164 - acc: 0.494 - ETA: 0s - loss: 0.7193 - acc: 0.485 - 0s - loss: 0.7191 - acc: 0.4838     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.8550 - acc: 0.593 - ETA: 0s - loss: 0.7878 - acc: 0.643 - ETA: 0s - loss: 0.7850 - acc: 0.663 - ETA: 0s - loss: 0.7558 - acc: 0.651 - ETA: 0s - loss: 0.7493 - acc: 0.641 - ETA: 0s - loss: 0.7574 - acc: 0.617 - ETA: 0s - loss: 0.7565 - acc: 0.614 - 0s - loss: 0.7502 - acc: 0.6206     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.9608 - acc: 0.406 - ETA: 0s - loss: 0.8075 - acc: 0.460 - ETA: 0s - loss: 0.8033 - acc: 0.468 - ETA: 0s - loss: 0.8000 - acc: 0.478 - ETA: 0s - loss: 0.8023 - acc: 0.480 - ETA: 0s - loss: 0.7834 - acc: 0.502 - ETA: 0s - loss: 0.7869 - acc: 0.498 - ETA: 0s - loss: 0.7736 - acc: 0.502 - ETA: 0s - loss: 0.7710 - acc: 0.503 - 0s - loss: 0.7713 - acc: 0.5037     \n",
      " 32/201 [===>..........................] - ETA: 0s[0, 0.59203980099502485, 0.1, 0.3]\n",
      "[1, 0.61691542288557211, 0.2, 0.1]\n",
      "[2, 0.55223880597014929, 0.3, 0.4]\n",
      "[3, 0.62686567164179108, 0.4, 0.1]\n",
      "[4, 0.57213930348258701, 0.4, 0.4]\n"
     ]
    }
   ],
   "source": [
    "''' CCN - Liu16'''\n",
    "\n",
    "accuracy_list =[]\n",
    "count =0\n",
    "for i in Y_new_list:\n",
    "    sample_weight = KLIEP_betas(X_train,i[0])\n",
    "    y= np_utils.to_categorical(i[0], 2)\n",
    "    model.fit(X_train,y,sample_weight=sample_weight, verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    #pred = pred0.argmax(axis=-1)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,i[1],i[2]])\n",
    "    count = count +1\n",
    "for i in accuracy_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.6944 - acc: 0.468 - ETA: 0s - loss: 0.6731 - acc: 0.500 - ETA: 0s - loss: 0.6813 - acc: 0.523 - ETA: 0s - loss: 0.6737 - acc: 0.528 - ETA: 0s - loss: 0.6707 - acc: 0.515 - ETA: 0s - loss: 0.6719 - acc: 0.509 - ETA: 0s - loss: 0.6699 - acc: 0.518 - ETA: 0s - loss: 0.6696 - acc: 0.508 - 0s - loss: 0.6704 - acc: 0.5077     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.7178 - acc: 0.531 - ETA: 0s - loss: 0.7368 - acc: 0.500 - ETA: 0s - loss: 0.7310 - acc: 0.482 - ETA: 0s - loss: 0.7261 - acc: 0.468 - ETA: 0s - loss: 0.7168 - acc: 0.477 - ETA: 0s - loss: 0.7128 - acc: 0.479 - ETA: 0s - loss: 0.7096 - acc: 0.486 - 0s - loss: 0.7028 - acc: 0.4956     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.6987 - acc: 0.468 - ETA: 0s - loss: 0.6400 - acc: 0.546 - ETA: 0s - loss: 0.6328 - acc: 0.543 - ETA: 0s - loss: 0.6584 - acc: 0.528 - ETA: 0s - loss: 0.6619 - acc: 0.513 - ETA: 0s - loss: 0.6595 - acc: 0.512 - ETA: 0s - loss: 0.6565 - acc: 0.528 - ETA: 0s - loss: 0.6551 - acc: 0.524 - 0s - loss: 0.6566 - acc: 0.5221     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.6433 - acc: 0.593 - ETA: 0s - loss: 0.6894 - acc: 0.445 - ETA: 0s - loss: 0.6821 - acc: 0.446 - ETA: 0s - loss: 0.6808 - acc: 0.425 - ETA: 0s - loss: 0.6699 - acc: 0.449 - ETA: 0s - loss: 0.6749 - acc: 0.455 - ETA: 0s - loss: 0.6731 - acc: 0.462 - ETA: 0s - loss: 0.6723 - acc: 0.466 - ETA: 0s - loss: 0.6705 - acc: 0.466 - 0s - loss: 0.6729 - acc: 0.4690     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.6376 - acc: 0.437 - ETA: 0s - loss: 0.6012 - acc: 0.468 - ETA: 0s - loss: 0.6287 - acc: 0.492 - ETA: 0s - loss: 0.6275 - acc: 0.491 - ETA: 0s - loss: 0.6229 - acc: 0.497 - ETA: 0s - loss: 0.6263 - acc: 0.483 - ETA: 0s - loss: 0.6306 - acc: 0.484 - ETA: 0s - loss: 0.6343 - acc: 0.485 - ETA: 0s - loss: 0.6400 - acc: 0.488 - 0s - loss: 0.6371 - acc: 0.4856     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.5949 - acc: 0.562 - ETA: 0s - loss: 0.6354 - acc: 0.507 - ETA: 0s - loss: 0.6448 - acc: 0.491 - ETA: 0s - loss: 0.6551 - acc: 0.493 - ETA: 0s - loss: 0.6584 - acc: 0.495 - ETA: 0s - loss: 0.6608 - acc: 0.496 - ETA: 0s - loss: 0.6565 - acc: 0.504 - ETA: 0s - loss: 0.6608 - acc: 0.497 - ETA: 0s - loss: 0.6589 - acc: 0.490 - 0s - loss: 0.6611 - acc: 0.4851     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.7046 - acc: 0.375 - ETA: 0s - loss: 0.6584 - acc: 0.489 - ETA: 0s - loss: 0.6702 - acc: 0.479 - ETA: 0s - loss: 0.6631 - acc: 0.472 - ETA: 0s - loss: 0.6645 - acc: 0.479 - ETA: 0s - loss: 0.6702 - acc: 0.458 - ETA: 0s - loss: 0.6684 - acc: 0.449 - ETA: 0s - loss: 0.6645 - acc: 0.456 - ETA: 0s - loss: 0.6626 - acc: 0.464 - ETA: 0s - loss: 0.6568 - acc: 0.456 - 0s - loss: 0.6558 - acc: 0.4541     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.6767 - acc: 0.468 - ETA: 0s - loss: 0.6544 - acc: 0.445 - ETA: 0s - loss: 0.6401 - acc: 0.442 - ETA: 0s - loss: 0.6288 - acc: 0.484 - ETA: 0s - loss: 0.6290 - acc: 0.473 - ETA: 0s - loss: 0.6312 - acc: 0.503 - ETA: 0s - loss: 0.6295 - acc: 0.490 - ETA: 0s - loss: 0.6302 - acc: 0.489 - ETA: 0s - loss: 0.6351 - acc: 0.492 - 0s - loss: 0.6343 - acc: 0.4906     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.6223 - acc: 0.500 - ETA: 0s - loss: 0.6213 - acc: 0.468 - ETA: 0s - loss: 0.6256 - acc: 0.477 - ETA: 0s - loss: 0.6236 - acc: 0.487 - ETA: 0s - loss: 0.6301 - acc: 0.488 - ETA: 0s - loss: 0.6267 - acc: 0.490 - ETA: 0s - loss: 0.6267 - acc: 0.498 - ETA: 0s - loss: 0.6289 - acc: 0.502 - ETA: 0s - loss: 0.6316 - acc: 0.507 - ETA: 0s - loss: 0.6262 - acc: 0.510 - 0s - loss: 0.6263 - acc: 0.5083     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.6652 - acc: 0.500 - ETA: 0s - loss: 0.6419 - acc: 0.484 - ETA: 0s - loss: 0.6446 - acc: 0.486 - ETA: 0s - loss: 0.6420 - acc: 0.468 - ETA: 0s - loss: 0.6425 - acc: 0.466 - ETA: 0s - loss: 0.6386 - acc: 0.480 - ETA: 0s - loss: 0.6352 - acc: 0.491 - ETA: 0s - loss: 0.6382 - acc: 0.484 - ETA: 0s - loss: 0.6408 - acc: 0.483 - ETA: 0s - loss: 0.6404 - acc: 0.484 - 0s - loss: 0.6413 - acc: 0.4840     \n",
      " 32/100 [========>.....................] - ETA: 0s[ 0.49743564] [ 0.07659962]\n"
     ]
    }
   ],
   "source": [
    "''' ILN - Liu16'''\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy_list =[]\n",
    "df_noise = pd.read_csv(csv_path)\n",
    "C_train = np.asarray(df_noise[\"Rater label\"])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(A_train,C_train):\n",
    "    x_train0, x_test0 = A_train[train_index], A_train[test_index]\n",
    "    y_train, y_test = C_train[train_index], C_train[test_index]\n",
    "\n",
    "    x_train1 = scaler.fit_transform(x_train0)\n",
    "    x_test1 = scaler.fit_transform(x_test0)\n",
    "\n",
    "    x_train = pca.fit_transform(x_train1)\n",
    "    x_test= pca.transform(x_test1)\n",
    "\n",
    "    sample_weight = KLIEP_betas(x_train,y_train)\n",
    "    y= np_utils.to_categorical(y_train, 2)\n",
    "    model.fit(x_train,y,sample_weight=sample_weight, verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(x_test)\n",
    "    a = accuracy_score(y_test,pred)\n",
    "    accuracy_list.append([a])\n",
    "print(np.mean(accuracy_list,axis=0),np.std(accuracy_list,axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
