{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the following packages before running the code:\n",
    "\n",
    "1/ cv2\n",
    "2/ tqdm\n",
    "3/ keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "''' Import key libraries'''\n",
    "import cv2 # using opencv to process image\n",
    "from tqdm import tqdm  # use tqdm to know the process of the iteration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os         \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "''' Preprocessing and Cross validation libraries'''\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "''' P libraries'''\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "train_path = r'C:\\Users\\phuph\\Desktop\\Spiderdatabase\\spidertrainset'\n",
    "csv_path = r'C:\\Users\\phuph\\Desktop\\Spiderdatabase\\spider_csv.csv'\n",
    "#test_path = 'test'\n",
    "\n",
    "size_img = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" From the image, record the label either dangerous or non\"\"\"\n",
    "def record_label(image_name):\n",
    "    label = image_name.split('.')[0]\n",
    "    if label == 'dangerous':\n",
    "        return 1\n",
    "    elif label == 'non':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" From the image, create the train data after resizing the image\"\"\"\n",
    "\n",
    "def create_train():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(train_path)):\n",
    "        path = os.path.join(train_path, img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img_data = cv2.resize(img_data, (size_img, size_img))\n",
    "        training_data.append([img_data, record_label(img) ])\n",
    "    #np.save('train_data.npy', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1005/1005 [00:11<00:00, 89.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train = create_train()\n",
    "#train = create_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_train = []\n",
    "for i in train:\n",
    "    a = i[0].reshape(-1)\n",
    "    A_train.append(a)\n",
    "A_train = np.asarray(A_train)\n",
    "B_train = np.asarray([i[1] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuph\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train0, X_test0, Y_train, Y_test = train_test_split(A_train, B_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuph\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train1 = scaler.fit_transform(X_train0)\n",
    "X_test1 = scaler.fit_transform(X_test0)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_train = pca.fit_transform(X_train1)\n",
    "X_test= pca.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Induce the CCN flip rate'''\n",
    "import random\n",
    "rho_po_list = [0.1,0.2,0.3,0.4,0.4]\n",
    "rho_ne_list = [0.3,0.1,0.4,0.1,0.4]\n",
    "Y_new_list = []\n",
    "for i in range(5):\n",
    "    rho_po = rho_po_list[i]\n",
    "    rho_ne = rho_ne_list[i]\n",
    "    Y_temp = np.copy(Y_train)\n",
    "    for j in range(len(Y_temp)):\n",
    "        if Y_train[j] ==1:\n",
    "            temp = random.random()\n",
    "            if temp < rho_po:\n",
    "                Y_temp[j] = 0\n",
    "        else:\n",
    "            t = random.random()\n",
    "            if t < rho_ne:\n",
    "                Y_temp[j] = 1\n",
    "    Y_new_list.append([Y_temp,rho_po,rho_ne])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 20 \n",
      "Number of classes: 2\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "''' Neural network model'''\n",
    "dims = X_train.shape[1]\n",
    "n_y = 2\n",
    "print( 'Number of features: %d ' %dims)\n",
    "print( 'Number of classes: %d' %n_y)\n",
    "print(\"Building model...\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_shape=(dims,)))\n",
    "model.add(Dense(60, input_shape=(dims,)))\n",
    "model.add(Dense(40, input_shape=(dims,)))\n",
    "model.add(Dense(n_y, input_shape=(dims,)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',sample_weight_mode=None,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 7.0405 - acc: 0.468 - ETA: 0s - loss: 5.9212 - acc: 0.556 - ETA: 0s - loss: 6.3105 - acc: 0.535 - ETA: 0s - loss: 6.2657 - acc: 0.531 - ETA: 0s - loss: 6.1502 - acc: 0.542 - ETA: 0s - loss: 6.0986 - acc: 0.549 - ETA: 0s - loss: 6.0582 - acc: 0.553 - ETA: 0s - loss: 6.3089 - acc: 0.539 - 0s - loss: 6.2109 - acc: 0.5473     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 6.6431 - acc: 0.562 - ETA: 0s - loss: 7.2973 - acc: 0.523 - ETA: 0s - loss: 7.8374 - acc: 0.482 - ETA: 0s - loss: 7.2227 - acc: 0.521 - ETA: 0s - loss: 6.8420 - acc: 0.533 - ETA: 0s - loss: 6.5801 - acc: 0.554 - ETA: 0s - loss: 6.4568 - acc: 0.564 - ETA: 0s - loss: 6.3735 - acc: 0.571 - ETA: 0s - loss: 6.4098 - acc: 0.571 - 0s - loss: 6.3981 - acc: 0.5721     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 5.6596 - acc: 0.593 - ETA: 0s - loss: 5.6646 - acc: 0.617 - ETA: 0s - loss: 5.8711 - acc: 0.607 - ETA: 0s - loss: 5.6329 - acc: 0.606 - ETA: 0s - loss: 5.7017 - acc: 0.601 - ETA: 0s - loss: 5.8353 - acc: 0.587 - ETA: 0s - loss: 5.8663 - acc: 0.582 - ETA: 0s - loss: 5.8483 - acc: 0.579 - ETA: 0s - loss: 5.8107 - acc: 0.572 - 0s - loss: 5.8403 - acc: 0.5709     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 3.3297 - acc: 0.781 - ETA: 0s - loss: 4.7185 - acc: 0.656 - ETA: 0s - loss: 5.5577 - acc: 0.607 - ETA: 0s - loss: 5.6927 - acc: 0.587 - ETA: 0s - loss: 5.3279 - acc: 0.613 - ETA: 0s - loss: 5.3503 - acc: 0.593 - ETA: 0s - loss: 5.0799 - acc: 0.582 - ETA: 0s - loss: 4.6673 - acc: 0.583 - ETA: 0s - loss: 4.3556 - acc: 0.580 - 0s - loss: 4.3425 - acc: 0.5796     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 4.7147 - acc: 0.531 - ETA: 0s - loss: 2.7994 - acc: 0.523 - ETA: 0s - loss: 2.2953 - acc: 0.508 - ETA: 0s - loss: 2.0849 - acc: 0.521 - ETA: 0s - loss: 1.9426 - acc: 0.502 - ETA: 0s - loss: 1.8699 - acc: 0.490 - ETA: 0s - loss: 1.8050 - acc: 0.486 - ETA: 0s - loss: 1.6839 - acc: 0.485 - ETA: 0s - loss: 1.6001 - acc: 0.488 - 0s - loss: 1.5949 - acc: 0.4888     \n",
      " 32/201 [===>..........................] - ETA: 0s[0, 0.58208955223880599, 0.1, 0.3]\n",
      "[1, 0.54228855721393032, 0.2, 0.1]\n",
      "[2, 0.56218905472636815, 0.3, 0.4]\n",
      "[3, 0.46766169154228854, 0.4, 0.1]\n",
      "[4, 0.51243781094527363, 0.4, 0.4]\n"
     ]
    }
   ],
   "source": [
    "''' Baseline - Accuracy'''\n",
    "\n",
    "accuracy_list =[]\n",
    "count =0\n",
    "for i in Y_new_list:\n",
    "    y= np_utils.to_categorical(i[0], 2)\n",
    "    model.fit(X_train,y, verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    #pred = pred0.argmax(axis=-1)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,i[1],i[2]])\n",
    "    count = count +1\n",
    "\n",
    "for i in accuracy_list:\n",
    "  #print(\"\\n Round %s \\n==============================\\n\" %i[0][0])\n",
    "  print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.6454 - acc: 0.562 - ETA: 0s - loss: 0.6473 - acc: 0.500 - ETA: 0s - loss: 0.5370 - acc: 0.531 - ETA: 0s - loss: 0.4913 - acc: 0.555 - ETA: 0s - loss: 0.4514 - acc: 0.580 - ETA: 0s - loss: 0.4319 - acc: 0.597 - ETA: 0s - loss: 0.4206 - acc: 0.595 - ETA: 0s - loss: 0.4137 - acc: 0.581 - ETA: 0s - loss: 0.4059 - acc: 0.565 - 0s - loss: 0.4031 - acc: 0.5659     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.6428 - acc: 0.500 - ETA: 0s - loss: 0.4886 - acc: 0.562 - ETA: 0s - loss: 0.4129 - acc: 0.588 - ETA: 0s - loss: 0.3868 - acc: 0.600 - ETA: 0s - loss: 0.3738 - acc: 0.599 - ETA: 0s - loss: 0.3760 - acc: 0.595 - ETA: 0s - loss: 0.3615 - acc: 0.621 - ETA: 0s - loss: 0.3591 - acc: 0.625 - ETA: 0s - loss: 0.3570 - acc: 0.623 - 0s - loss: 0.3551 - acc: 0.6269     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.4175 - acc: 0.562 - ETA: 0s - loss: 0.4012 - acc: 0.507 - ETA: 0s - loss: 0.4033 - acc: 0.492 - ETA: 0s - loss: 0.3966 - acc: 0.508 - ETA: 0s - loss: 0.3930 - acc: 0.516 - ETA: 0s - loss: 0.3932 - acc: 0.513 - ETA: 0s - loss: 0.3909 - acc: 0.517 - ETA: 0s - loss: 0.3857 - acc: 0.535 - 0s - loss: 0.3850 - acc: 0.5386     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.3414 - acc: 0.593 - ETA: 0s - loss: 0.3261 - acc: 0.617 - ETA: 0s - loss: 0.3319 - acc: 0.578 - ETA: 0s - loss: 0.3282 - acc: 0.565 - ETA: 0s - loss: 0.3205 - acc: 0.578 - ETA: 0s - loss: 0.3176 - acc: 0.584 - ETA: 0s - loss: 0.3233 - acc: 0.571 - ETA: 0s - loss: 0.3183 - acc: 0.574 - 0s - loss: 0.3142 - acc: 0.5759     \n",
      " 32/201 [===>..........................] - ETA: 0sEpoch 1/1\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.3818 - acc: 0.718 - ETA: 0s - loss: 0.3815 - acc: 0.687 - ETA: 0s - loss: 0.3923 - acc: 0.656 - ETA: 0s - loss: 0.3931 - acc: 0.611 - ETA: 0s - loss: 0.3862 - acc: 0.597 - ETA: 0s - loss: 0.3878 - acc: 0.572 - ETA: 0s - loss: 0.3841 - acc: 0.568 - ETA: 0s - loss: 0.3850 - acc: 0.557 - ETA: 0s - loss: 0.3821 - acc: 0.557 - ETA: 0s - loss: 0.3850 - acc: 0.554 - ETA: 0s - loss: 0.3831 - acc: 0.547 - 0s - loss: 0.3826 - acc: 0.5485     \n",
      " 32/201 [===>..........................] - ETA: 0s[0, 0.57213930348258701, 0.1, 0.3]\n",
      "[1, 0.58706467661691542, 0.2, 0.1]\n",
      "[2, 0.57213930348258701, 0.3, 0.4]\n",
      "[3, 0.57213930348258701, 0.4, 0.1]\n",
      "[4, 0.55223880597014929, 0.4, 0.4]\n"
     ]
    }
   ],
   "source": [
    "''' Nat13 - Accuracy'''\n",
    "\n",
    "accuracy_list =[]\n",
    "count =0\n",
    "for i in Y_new_list:\n",
    "    alpha = float(1 - i[1] + i[2]) / 2\n",
    "    y = i[0]\n",
    "    sample_weight = (1-alpha)*np.ones(np.shape(y)) \n",
    "    sample_weight[y==0] = alpha\n",
    "    y= np_utils.to_categorical(i[0], 2)\n",
    "    model.fit(X_train,y,sample_weight=sample_weight, verbose=1,epochs=1)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    #pred = pred0.argmax(axis=-1)\n",
    "    a = accuracy_score(Y_test,pred)\n",
    "    accuracy_list.append([count,a,i[1],i[2]])\n",
    "    count = count +1\n",
    "for i in accuracy_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuph\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.8211 - acc: 0.500 - ETA: 0s - loss: 0.7520 - acc: 0.489 - ETA: 0s - loss: 0.7559 - acc: 0.481 - ETA: 0s - loss: 0.7502 - acc: 0.482 - ETA: 0s - loss: 0.7380 - acc: 0.500 - ETA: 0s - loss: 0.7357 - acc: 0.505 - ETA: 0s - loss: 0.7333 - acc: 0.515 - ETA: 0s - loss: 0.7306 - acc: 0.520 - ETA: 0s - loss: 0.7231 - acc: 0.532 - ETA: 0s - loss: 0.7180 - acc: 0.541 - ETA: 0s - loss: 0.7107 - acc: 0.554 - ETA: 0s - loss: 0.7173 - acc: 0.547 - ETA: 0s - loss: 0.7180 - acc: 0.541 - 0s - loss: 0.7159 - acc: 0.5431     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.7619 - acc: 0.500 - ETA: 0s - loss: 0.8067 - acc: 0.500 - ETA: 0s - loss: 0.7658 - acc: 0.526 - ETA: 0s - loss: 0.7633 - acc: 0.507 - ETA: 0s - loss: 0.7477 - acc: 0.506 - ETA: 0s - loss: 0.7501 - acc: 0.500 - ETA: 0s - loss: 0.7440 - acc: 0.506 - ETA: 0s - loss: 0.7387 - acc: 0.520 - ETA: 0s - loss: 0.7377 - acc: 0.516 - ETA: 0s - loss: 0.7328 - acc: 0.520 - ETA: 0s - loss: 0.7323 - acc: 0.520 - ETA: 0s - loss: 0.7297 - acc: 0.527 - ETA: 0s - loss: 0.7280 - acc: 0.520 - 0s - loss: 0.7284 - acc: 0.5188     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.7369 - acc: 0.500 - ETA: 0s - loss: 0.7230 - acc: 0.531 - ETA: 0s - loss: 0.7219 - acc: 0.518 - ETA: 0s - loss: 0.7263 - acc: 0.504 - ETA: 0s - loss: 0.7194 - acc: 0.503 - ETA: 0s - loss: 0.7164 - acc: 0.517 - ETA: 0s - loss: 0.7239 - acc: 0.512 - ETA: 0s - loss: 0.7253 - acc: 0.502 - ETA: 0s - loss: 0.7259 - acc: 0.501 - ETA: 0s - loss: 0.7293 - acc: 0.498 - ETA: 0s - loss: 0.7297 - acc: 0.498 - ETA: 0s - loss: 0.7249 - acc: 0.508 - ETA: 0s - loss: 0.7224 - acc: 0.511 - ETA: 0s - loss: 0.7236 - acc: 0.503 - 0s - loss: 0.7234 - acc: 0.5033     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.6944 - acc: 0.531 - ETA: 0s - loss: 0.7316 - acc: 0.510 - ETA: 0s - loss: 0.7289 - acc: 0.531 - ETA: 0s - loss: 0.7219 - acc: 0.526 - ETA: 0s - loss: 0.7175 - acc: 0.534 - ETA: 0s - loss: 0.7124 - acc: 0.522 - ETA: 0s - loss: 0.7112 - acc: 0.531 - ETA: 0s - loss: 0.7082 - acc: 0.527 - ETA: 0s - loss: 0.7115 - acc: 0.527 - ETA: 0s - loss: 0.7117 - acc: 0.528 - ETA: 0s - loss: 0.7121 - acc: 0.526 - ETA: 0s - loss: 0.7155 - acc: 0.519 - ETA: 0s - loss: 0.7152 - acc: 0.522 - ETA: 0s - loss: 0.7139 - acc: 0.526 - 0s - loss: 0.7166 - acc: 0.5243     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.8329 - acc: 0.281 - ETA: 0s - loss: 0.7394 - acc: 0.447 - ETA: 0s - loss: 0.7374 - acc: 0.468 - ETA: 0s - loss: 0.7284 - acc: 0.464 - ETA: 0s - loss: 0.7169 - acc: 0.489 - ETA: 0s - loss: 0.7216 - acc: 0.483 - ETA: 0s - loss: 0.7222 - acc: 0.490 - ETA: 0s - loss: 0.7187 - acc: 0.491 - ETA: 0s - loss: 0.7225 - acc: 0.489 - ETA: 0s - loss: 0.7208 - acc: 0.495 - ETA: 0s - loss: 0.7193 - acc: 0.500 - ETA: 0s - loss: 0.7182 - acc: 0.512 - ETA: 0s - loss: 0.7133 - acc: 0.522 - ETA: 0s - loss: 0.7121 - acc: 0.525 - 0s - loss: 0.7144 - acc: 0.5221     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.8429 - acc: 0.437 - ETA: 0s - loss: 0.7833 - acc: 0.416 - ETA: 0s - loss: 0.7558 - acc: 0.450 - ETA: 0s - loss: 0.7471 - acc: 0.464 - ETA: 0s - loss: 0.7284 - acc: 0.486 - ETA: 0s - loss: 0.7335 - acc: 0.491 - ETA: 0s - loss: 0.7314 - acc: 0.492 - ETA: 0s - loss: 0.7348 - acc: 0.485 - ETA: 0s - loss: 0.7289 - acc: 0.490 - ETA: 0s - loss: 0.7273 - acc: 0.498 - ETA: 0s - loss: 0.7301 - acc: 0.495 - ETA: 0s - loss: 0.7283 - acc: 0.500 - ETA: 0s - loss: 0.7262 - acc: 0.503 - ETA: 0s - loss: 0.7253 - acc: 0.510 - 0s - loss: 0.7279 - acc: 0.5072     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.6276 - acc: 0.593 - ETA: 0s - loss: 0.7153 - acc: 0.510 - ETA: 0s - loss: 0.7144 - acc: 0.487 - ETA: 0s - loss: 0.7139 - acc: 0.495 - ETA: 0s - loss: 0.7175 - acc: 0.496 - ETA: 0s - loss: 0.7248 - acc: 0.478 - ETA: 0s - loss: 0.7166 - acc: 0.489 - ETA: 0s - loss: 0.7172 - acc: 0.495 - ETA: 0s - loss: 0.7156 - acc: 0.494 - ETA: 0s - loss: 0.7196 - acc: 0.489 - ETA: 0s - loss: 0.7197 - acc: 0.489 - ETA: 0s - loss: 0.7179 - acc: 0.491 - ETA: 0s - loss: 0.7188 - acc: 0.489 - ETA: 0s - loss: 0.7188 - acc: 0.492 - ETA: 0s - loss: 0.7196 - acc: 0.493 - 0s - loss: 0.7205 - acc: 0.4906     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.8166 - acc: 0.281 - ETA: 0s - loss: 0.7076 - acc: 0.489 - ETA: 0s - loss: 0.7010 - acc: 0.525 - ETA: 0s - loss: 0.6933 - acc: 0.553 - ETA: 0s - loss: 0.6990 - acc: 0.555 - ETA: 0s - loss: 0.6944 - acc: 0.542 - ETA: 0s - loss: 0.6953 - acc: 0.548 - ETA: 0s - loss: 0.7017 - acc: 0.535 - ETA: 0s - loss: 0.7009 - acc: 0.529 - ETA: 0s - loss: 0.6991 - acc: 0.539 - ETA: 0s - loss: 0.7018 - acc: 0.526 - ETA: 0s - loss: 0.7033 - acc: 0.528 - ETA: 0s - loss: 0.7028 - acc: 0.527 - ETA: 0s - loss: 0.7043 - acc: 0.527 - 0s - loss: 0.7064 - acc: 0.5227     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.7801 - acc: 0.406 - ETA: 0s - loss: 0.7347 - acc: 0.510 - ETA: 0s - loss: 0.7315 - acc: 0.525 - ETA: 0s - loss: 0.7235 - acc: 0.535 - ETA: 0s - loss: 0.7171 - acc: 0.527 - ETA: 0s - loss: 0.7166 - acc: 0.525 - ETA: 0s - loss: 0.7055 - acc: 0.533 - ETA: 0s - loss: 0.7089 - acc: 0.533 - ETA: 0s - loss: 0.7000 - acc: 0.547 - ETA: 0s - loss: 0.6982 - acc: 0.552 - ETA: 0s - loss: 0.6960 - acc: 0.553 - ETA: 0s - loss: 0.7033 - acc: 0.547 - ETA: 0s - loss: 0.7019 - acc: 0.546 - ETA: 0s - loss: 0.6985 - acc: 0.552 - 0s - loss: 0.6982 - acc: 0.5536     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.7571 - acc: 0.437 - ETA: 0s - loss: 0.7273 - acc: 0.510 - ETA: 0s - loss: 0.7162 - acc: 0.512 - ETA: 0s - loss: 0.7107 - acc: 0.504 - ETA: 0s - loss: 0.7007 - acc: 0.548 - ETA: 0s - loss: 0.7191 - acc: 0.522 - ETA: 0s - loss: 0.7180 - acc: 0.521 - ETA: 0s - loss: 0.7216 - acc: 0.508 - ETA: 0s - loss: 0.7226 - acc: 0.514 - ETA: 0s - loss: 0.7214 - acc: 0.518 - ETA: 0s - loss: 0.7182 - acc: 0.514 - ETA: 0s - loss: 0.7179 - acc: 0.513 - ETA: 0s - loss: 0.7157 - acc: 0.516 - ETA: 0s - loss: 0.7112 - acc: 0.525 - 0s - loss: 0.7109 - acc: 0.5271     \n",
      " 32/100 [========>.....................] - ETA: 0s[ 0.47748515] [ 0.06313732]\n"
     ]
    }
   ],
   "source": [
    "''' ILN - Baseline '''\n",
    "\n",
    "\n",
    "accuracy_list =[]\n",
    "df_noise = pd.read_csv(csv_path)\n",
    "C_train = np.asarray(df_noise[\"Rater label\"])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(A_train,C_train):\n",
    "    x_train0, x_test0 = A_train[train_index], A_train[test_index]\n",
    "    y_train, y_test = C_train[train_index], C_train[test_index]\n",
    "    x_train1 = scaler.fit_transform(x_train0)\n",
    "    x_test1 = scaler.fit_transform(x_test0)\n",
    "\n",
    "    x_train = pca.fit_transform(x_train1)\n",
    "    x_test= pca.transform(x_test1)\n",
    "    y= np_utils.to_categorical(y_train, 2)\n",
    "    model.fit(x_train, y,verbose=1, epochs=1)\n",
    "    pred = model.predict_classes(x_test)\n",
    "    a = accuracy_score(y_test,pred)\n",
    "    accuracy_list.append([a])\n",
    "    \n",
    "print(np.mean(accuracy_list,axis=0),np.std(accuracy_list,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phuph\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.3584 - acc: 0.562 - ETA: 0s - loss: 0.3703 - acc: 0.541 - ETA: 0s - loss: 0.3686 - acc: 0.531 - ETA: 0s - loss: 0.3687 - acc: 0.513 - ETA: 0s - loss: 0.3576 - acc: 0.545 - ETA: 0s - loss: 0.3569 - acc: 0.554 - ETA: 0s - loss: 0.3542 - acc: 0.552 - ETA: 0s - loss: 0.3525 - acc: 0.554 - ETA: 0s - loss: 0.3506 - acc: 0.555 - ETA: 0s - loss: 0.3502 - acc: 0.557 - ETA: 0s - loss: 0.3497 - acc: 0.559 - ETA: 0s - loss: 0.3478 - acc: 0.565 - ETA: 0s - loss: 0.3483 - acc: 0.560 - 0s - loss: 0.3490 - acc: 0.5575     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 1s - loss: 0.3747 - acc: 0.437 - ETA: 0s - loss: 0.3641 - acc: 0.447 - ETA: 0s - loss: 0.3570 - acc: 0.493 - ETA: 0s - loss: 0.3548 - acc: 0.486 - ETA: 0s - loss: 0.3542 - acc: 0.496 - ETA: 0s - loss: 0.3542 - acc: 0.494 - ETA: 0s - loss: 0.3549 - acc: 0.485 - ETA: 0s - loss: 0.3524 - acc: 0.497 - ETA: 0s - loss: 0.3515 - acc: 0.506 - ETA: 0s - loss: 0.3516 - acc: 0.501 - ETA: 0s - loss: 0.3506 - acc: 0.511 - ETA: 0s - loss: 0.3509 - acc: 0.515 - 0s - loss: 0.3502 - acc: 0.5188     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.3418 - acc: 0.437 - ETA: 0s - loss: 0.3504 - acc: 0.484 - ETA: 0s - loss: 0.3476 - acc: 0.491 - ETA: 0s - loss: 0.3422 - acc: 0.518 - ETA: 0s - loss: 0.3458 - acc: 0.519 - ETA: 0s - loss: 0.3476 - acc: 0.515 - ETA: 0s - loss: 0.3478 - acc: 0.526 - ETA: 0s - loss: 0.3500 - acc: 0.521 - ETA: 0s - loss: 0.3505 - acc: 0.511 - ETA: 0s - loss: 0.3485 - acc: 0.503 - ETA: 0s - loss: 0.3479 - acc: 0.509 - ETA: 0s - loss: 0.3465 - acc: 0.504 - 0s - loss: 0.3462 - acc: 0.5044     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.3683 - acc: 0.437 - ETA: 0s - loss: 0.3641 - acc: 0.492 - ETA: 0s - loss: 0.3581 - acc: 0.486 - ETA: 0s - loss: 0.3521 - acc: 0.481 - ETA: 0s - loss: 0.3524 - acc: 0.485 - ETA: 0s - loss: 0.3504 - acc: 0.482 - ETA: 0s - loss: 0.3503 - acc: 0.484 - ETA: 0s - loss: 0.3503 - acc: 0.485 - ETA: 0s - loss: 0.3505 - acc: 0.484 - ETA: 0s - loss: 0.3486 - acc: 0.497 - ETA: 0s - loss: 0.3496 - acc: 0.500 - ETA: 0s - loss: 0.3493 - acc: 0.497 - 0s - loss: 0.3491 - acc: 0.5011     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "904/904 [==============================] - ETA: 0s - loss: 0.3430 - acc: 0.531 - ETA: 0s - loss: 0.3455 - acc: 0.531 - ETA: 0s - loss: 0.3450 - acc: 0.525 - ETA: 0s - loss: 0.3433 - acc: 0.540 - ETA: 0s - loss: 0.3450 - acc: 0.541 - ETA: 0s - loss: 0.3425 - acc: 0.548 - ETA: 0s - loss: 0.3440 - acc: 0.545 - ETA: 0s - loss: 0.3436 - acc: 0.552 - ETA: 0s - loss: 0.3444 - acc: 0.546 - ETA: 0s - loss: 0.3432 - acc: 0.554 - ETA: 0s - loss: 0.3429 - acc: 0.558 - ETA: 0s - loss: 0.3425 - acc: 0.558 - ETA: 0s - loss: 0.3413 - acc: 0.566 - ETA: 0s - loss: 0.3421 - acc: 0.562 - 0s - loss: 0.3420 - acc: 0.5619     \n",
      " 32/101 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.3593 - acc: 0.562 - ETA: 1s - loss: 0.3506 - acc: 0.593 - ETA: 0s - loss: 0.3532 - acc: 0.554 - ETA: 0s - loss: 0.3503 - acc: 0.541 - ETA: 0s - loss: 0.3502 - acc: 0.562 - ETA: 0s - loss: 0.3479 - acc: 0.562 - ETA: 0s - loss: 0.3489 - acc: 0.554 - ETA: 0s - loss: 0.3472 - acc: 0.554 - ETA: 0s - loss: 0.3466 - acc: 0.547 - ETA: 0s - loss: 0.3460 - acc: 0.542 - ETA: 0s - loss: 0.3439 - acc: 0.537 - ETA: 0s - loss: 0.3449 - acc: 0.534 - ETA: 0s - loss: 0.3445 - acc: 0.532 - ETA: 0s - loss: 0.3449 - acc: 0.526 - 0s - loss: 0.3450 - acc: 0.5260     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.3750 - acc: 0.562 - ETA: 0s - loss: 0.3558 - acc: 0.510 - ETA: 0s - loss: 0.3515 - acc: 0.543 - ETA: 0s - loss: 0.3529 - acc: 0.531 - ETA: 0s - loss: 0.3542 - acc: 0.531 - ETA: 0s - loss: 0.3558 - acc: 0.519 - ETA: 0s - loss: 0.3507 - acc: 0.545 - ETA: 0s - loss: 0.3525 - acc: 0.533 - ETA: 0s - loss: 0.3518 - acc: 0.534 - ETA: 0s - loss: 0.3519 - acc: 0.526 - ETA: 0s - loss: 0.3523 - acc: 0.526 - ETA: 0s - loss: 0.3536 - acc: 0.525 - ETA: 0s - loss: 0.3532 - acc: 0.531 - ETA: 0s - loss: 0.3535 - acc: 0.533 - 0s - loss: 0.3551 - acc: 0.5249     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.3557 - acc: 0.562 - ETA: 0s - loss: 0.3355 - acc: 0.604 - ETA: 0s - loss: 0.3431 - acc: 0.537 - ETA: 0s - loss: 0.3400 - acc: 0.544 - ETA: 0s - loss: 0.3462 - acc: 0.506 - ETA: 0s - loss: 0.3465 - acc: 0.508 - ETA: 0s - loss: 0.3461 - acc: 0.514 - ETA: 0s - loss: 0.3475 - acc: 0.514 - ETA: 0s - loss: 0.3461 - acc: 0.523 - ETA: 0s - loss: 0.3453 - acc: 0.524 - ETA: 0s - loss: 0.3460 - acc: 0.520 - ETA: 0s - loss: 0.3452 - acc: 0.527 - ETA: 0s - loss: 0.3452 - acc: 0.526 - ETA: 0s - loss: 0.3465 - acc: 0.520 - ETA: 0s - loss: 0.3477 - acc: 0.517 - 0s - loss: 0.3476 - acc: 0.5171     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.3149 - acc: 0.687 - ETA: 0s - loss: 0.3378 - acc: 0.645 - ETA: 0s - loss: 0.3453 - acc: 0.606 - ETA: 0s - loss: 0.3481 - acc: 0.589 - ETA: 0s - loss: 0.3475 - acc: 0.583 - ETA: 0s - loss: 0.3424 - acc: 0.588 - ETA: 0s - loss: 0.3401 - acc: 0.601 - ETA: 0s - loss: 0.3428 - acc: 0.587 - ETA: 0s - loss: 0.3435 - acc: 0.580 - ETA: 0s - loss: 0.3438 - acc: 0.583 - ETA: 0s - loss: 0.3443 - acc: 0.589 - ETA: 0s - loss: 0.3433 - acc: 0.584 - ETA: 0s - loss: 0.3459 - acc: 0.580 - ETA: 0s - loss: 0.3474 - acc: 0.575 - 0s - loss: 0.3472 - acc: 0.5746     \n",
      " 32/100 [========>.....................] - ETA: 0sEpoch 1/1\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.3582 - acc: 0.593 - ETA: 0s - loss: 0.3603 - acc: 0.552 - ETA: 0s - loss: 0.3649 - acc: 0.550 - ETA: 0s - loss: 0.3644 - acc: 0.531 - ETA: 0s - loss: 0.3646 - acc: 0.503 - ETA: 0s - loss: 0.3643 - acc: 0.511 - ETA: 0s - loss: 0.3589 - acc: 0.528 - ETA: 0s - loss: 0.3592 - acc: 0.533 - ETA: 0s - loss: 0.3576 - acc: 0.526 - ETA: 0s - loss: 0.3549 - acc: 0.528 - ETA: 0s - loss: 0.3550 - acc: 0.528 - ETA: 0s - loss: 0.3527 - acc: 0.535 - ETA: 0s - loss: 0.3518 - acc: 0.542 - ETA: 0s - loss: 0.3517 - acc: 0.542 - 0s - loss: 0.3517 - acc: 0.5414     \n",
      " 32/100 [========>.....................] - ETA: 0s[ 0.49644554] [ 0.07353003]\n"
     ]
    }
   ],
   "source": [
    "''' ILN - Nat13 Accuracy '''\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy_list =[]\n",
    "df_noise = pd.read_csv(csv_path)\n",
    "C_train = np.asarray(df_noise[\"Rater label\"])\n",
    "\n",
    "rho_po_list = [0.2,0.3,0.4,0.1]\n",
    "rho_ne_list = [0.2,0.1,0.4,0.3]\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index,test_index in skf.split(A_train,C_train):\n",
    "    x_train0, x_test0 = A_train[train_index], A_train[test_index]\n",
    "    y_train, y_test = C_train[train_index], C_train[test_index]\n",
    "    x_train1 = scaler.fit_transform(x_train0)\n",
    "    x_test1 = scaler.fit_transform(x_test0)\n",
    "\n",
    "    x_train = pca.fit_transform(x_train1)\n",
    "    x_test= pca.transform(x_test1)\n",
    "    rho_po = random.choice(rho_po_list)\n",
    "    rho_ne = random.choice(rho_ne_list)\n",
    "    \n",
    "    alpha = float(1 - rho_po + rho_ne) / 2\n",
    "    y = y_train\n",
    "    sample_weight = (1-alpha)*np.ones(np.shape(y)) \n",
    "    sample_weight[y==0] = alpha\n",
    "    \n",
    "    y= np_utils.to_categorical(y_train, 2)\n",
    "    model.fit(x_train, y,sample_weight = sample_weight,verbose=1, epochs=1)\n",
    "    pred = model.predict_classes(x_test)\n",
    "    a = accuracy_score(y_test,pred)\n",
    "    accuracy_list.append([a])\n",
    "    \n",
    "print(np.mean(accuracy_list,axis=0),np.std(accuracy_list,axis=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
